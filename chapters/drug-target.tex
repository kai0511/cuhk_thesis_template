\chapter{Drug Target Discovery}

\section{Introduction}
  \subsection{Motivation}
    Traditionally, drug discovery involves five steps: target identification, target validation, lead identification, lead optimization and introduction of the new drugs to the public \cite{phoebe2008identifying}. Nevertheless, the speed of new drug development has been slower than anticipated, despite increasing investment \cite{pammolli2011productivity}. It is estimated that the cost of developing a new drug is ~USD 2.6 billion \cite{van1998socio}. One of the main reasons for the enormous cost of drug discovery is due to the high failure rate. 

    Success of drug development largely depends on the validity of targets. However, the majority of drugs fail to complete the development process due to lack of efficacy, and this is often due to the wrong target being pursued \cite{shih2018drug}. Traditionally, drug targets are often identified from hypothesis-driven preclinical models, yet preclinical models may not always translate well to clinical applications. For some diseases such as psychiatric disorders, current animal or cell models are still far from capturing the complexity of the human disorder \cite{nestler2010animal}. In addition, some have hypothesized the hypothesis-driven nature of many studies may have led to "filtering" of findings and publication bias, exacerbating the reliability and reproducibility issues of some research findings. On the other hand, the recent decade has witnessed a remarkable growth in “omics” and other forms of big data. As increasing amount of biomedical data has been made available, computational methods can offer a fast, cost-effective and unbiased way to prioritize promising drug targets. Given the limitation of current approaches and the urgent need to develop therapies for diseases, addressing the problem of target identification and drug development from different angles is essential. We believe that computational and experimental approaches can complement each other to improve the efficiency and reliability of drug target finding.  
  
    In the study, we present a flexible novel computational target discovery framework, in which various machine learning (ML) methods can be adopted. It is a data-driven approach to prioritize drug targets for specific diseases, and is independent from most other kinds of evidences e.g. animal models, top genes from GWAS or sequencing studies etc., which are listed  in OpenTargets \cite{koscielny2017open}, one of the largest drug target databases to date. Specifically, we employ ML methods to drug-induced expression profiles with indication as the outcome variable to \textit{learn the pattern of gene expression contributing to treatment potential}; we then applied the fitted models to transcriptome data derived from gene perturbations (i.e. over-expression [OE] or knock-down [KD] of specific genes) to predict "treatment potential" of OE/KD of specific genes. We could then prioritize drug targets based on the predicted probabilities. 

    Intuitively, for example, over-expression (OE) of gene\textit{ X} leads to an expression profile similar to that of five other drugs that are known to treat diabetes. Then an agonist targeted at \textit{X }(or other drugs that activate\textit{ X }and related pathways) may also be useful for treating diabetes. In this case we expect the ML model (trained on drugs but applied to gene perturbation data) would output a \textit{high }predicted probability for gene \textit{X}, which can be prioritized for further studies. Let us consider an opposite scenario in which over-expression of gene \textit{Y }\textit{increases} the disease risk. In this case we may observe a \textit{lower}-than-expected predicted probability of ‘treatment potential’ from the ML model. In this case down-regulation of gene Y may be beneficial for treatment. 

  \subsection{Related Works}
    Kandoi et al. has reviewed applications of ML and system biology on the discovery of target proteins \cite{kandoi2015prediction}. In these applications, different kinds of biological properties have been explored using ML methods to identify druggable targets \cite{bakheet2009properties, fauman2011structure, li2015large,kumari2015identification, li2007prediction}. A sequence-based prediction method was proposed to identify drug target proteins based on biological features like amino acid composition, and a comprehensive comparison of several machine learning methods was conducted \cite{kumari2015identification}. In another study \cite{bakheet2009properties}, eight key properties of human drug target were summarized, and support vector machine (SVM) was employed to build a classifier on these properties to predict probabilities of potential targets. In a similar study, the authors extracted physicochemical properties from known drug targets, trained a classifier with these properties, and listed possible drug targets by predicted probabilities from the classifier \cite{li2007prediction}. Network-based methods also were employed to identify potential drug targets using topological features of human protein–protein interaction network \cite{li2015large}. These studies aimed to discover new targets by making use of structural attributes, but gene-disease association data such as gene expression profiles may also be used to identify target genes \cite{emig2013drug, ferrero2017silico, sawada2018predicting, costa2010machine}. In a recent study, gene-disease association data from Open Targets was explored by employing four different ML methods to find novel targets \cite{ferrero2017silico}. Emig et. al. proposed an integrated network-based method to predict drug targets based on disease gene expression profiles and a high-quality interaction network, and some novel drug targets for scleroderma and other types of cancer were presented \cite{emig2013drug}. A most recent study constructed pairwise learning and joint learning methods on chemically and genetically perturbed gene expression profiles to predict drug targets\cite{sawada2018predicting}. 

    However, our study is different from the previous studies in several aspects. Some of the previous works (e.g.\cite {ferrero2017silico, bakheet2009properties, kumari2015identification, li2007prediction}) aimed to predict general therapeutic targets, instead of targets for specific diseases. Some employed network-based methods (e.g. \cite{sawada2018predicting, li2015large, emig2013drug}) for target prediction, which is powerful approach. However, they are relatively dependent on similarity between entities, hence less capable of discovering novel drug targets. Here we employed an ML approach to predict potential drug targets. An advantage is that the method is general and highly flexible, and any ML methodologies including newly developed ones may be used. A recent study  \cite{sawada2018predicting} also employed gene perturbation to predict drug targets. However, the methodologies and aims of our study and \cite{sawada2018predicting} are different. The present work proposed the use of ML methods to assess how the expression profiles from gene perturbations are related to those of drugs. \cite{sawada2018predicting} mainly employed Pearson correlation and linear models to assess the similarity between transcriptomic changes from gene perturbation and those from drugs. An advantage of our approach is that different kinds of ML methods (e.g. SVM, random forests, boosted trees) may be used, which may accommodate complex non-linear relationships and possibly interactions between features.  \cite {sawada2018predicting} used transcriptomic data from gene perturbations mainly to predict drug-protein interactions; prediction of \textit{disease-specific} drug targets was performed in another analysis using networks. Here we proposed integrating transcriptomic data with ML approaches in a unified framework to predict drug targets \textit{ for specific diseases}. We also note a previous study of ours has employed an ML approach for drug repositioning \cite{zhao2018drug}; however here our aim is to uncover new \textit{drug targets}. Drug repositioning may not always be feasible (for example due to side-effects of existing drugs), and revealing new targets remains an important goal in drug development and pharmacological research. Besides, unlike the previous work, we have covered diseases other than psychiatric disorders. 
    
     Validation of drug-disease or drug-target predictions from computational methods has always been a difficult task. As reported by \cite{guney2017reproducible}, a cross-validation approach may over-estimate predictive accuracy, as the training and testing set may have overlapping drugs. Also, drugs that are highly similar may be split into train and test sets, hence the similarity of training and testing set may be higher than anticipated in real-life scenarios. Some studies evaluate validity of results using performance evaluation metrics (e.g. AUC-ROC) under the framework of cross-validation, which may lead to overoptimistic results. To avoid this problem, we utilized an independent resource to examine whether our approach can 'rediscover' known drug targets for diseases. Briefly, we performed validation of our results by assessing for enrichment of targets listed by Open Targets \cite{koscielny2017open}, a platform for systematic drug target identification and prioritization. The platform integrates data from genetics, somatic mutations, expression analysis, drugs, animal models and the literature through robust pipelines and uses an aggregate score to indicate the association of a target with disease \cite{koscielny2017open}.

    In summary, we first proposed a general framework for identifying drug targets of specific diseases, based on ML using expression profiles. The methodology was applied to a number of diseases including type 2 diabetes mellitus (DM), hypertension (HT), schizophrenia (SCZ), bipolar disorder (BP) and  rheumatoid arthritis (RA). We then validated the approach by assessing its ability to 'rediscover' drug targets based on an external established database. We also found that many candidate targets are supported by the literature and are functionally relevant. 

\section{Datasets and Methods}
  \subsection{Datasets}
    The gene expression profiles were downloaded from the website\footnote{https://github.com/dhimmel/lincs.}, and consensus transcriptional signatures have been computed for the expression profiles from the Library of Integrated Network Based Cellular Signatures (LINCS) L1000 perturbations \cite{subramanian2017next}. The data includes expression profiles induced by drugs and by over-expression (OE) or knockdown (KD) of specific genes. 

    We kept genes with expression data present in both data-sets. The LINCS drug expression dataset consisted of 1158 observations, with expression data of 7467 genes. OE and KD expression datasets consisted of 2413 and 4326 samples respectively, with expression data for 7467 genes. 

    Drug indications were extracted from Anatomical Therapeutic Chemical (ATC) classification system and the MEDication Indication Resource high precision subset (MEDI-HPS) \cite{wei2013development}. The MEDI-HPS indication resource includes indications extracted from RxNorm, SIDER Side Effect Resource, MedlinePlus, and Wikipedia \cite{wei2013development}. The high-precision subset (HPS) only considers medications indicated by RxNorm or those that appear in two out of three resources.HPS contains 13,304 unique indications for 2,136 medications \cite{wei2013development}. Further validation of MEDI-HPS was also provided in a further study \cite{wei2013validation}. 

    In the study, the code N05A of ATC was considered as the category of treatments for SCZ, and we used the same category for both SCZ and BP. Drugs under C02 and A10 of ATC were considered as treatments for HT and DM respectively. Drugs in MEDI-HPS are classified by ICD9, and then we used drugs under 714.0 for treatments of rheumatoid arthritis.

  \subsection{Methods}
    Here we proposed a general computational framework for prioritizing drug targets for further study, in which any classification algorithms are applicable. In this study, several ML methods, including support vector machine (SVM) \cite{cortes1995support}, gradient boosting machine (GBM) with trees \cite{friedman2001greedy}, random forest (RF) \cite{breiman2001random} and logistic regression with elastic net penalty (EN) \cite{zou2005regularization} were employed for prediction modelling. 

    In the first step, we utilized the above ML methods to predict the 'treatment potential' of each drug for each disease under study. The gene expression were considered as features (predictors), while the indication (whether the drug indicated for the studied disease; coded 0 or 1) was considered as the outcome.  The prediction model was then applied to expression profiles resulted from OE/KD to predict the probabilities of 'treatment potential' by over-expressing or knocking down corresponding genes. As explained in the introduction, particularly high or low predicted probabilities may indicate the gene as a potential drug target. 

    In this study we studied five kinds of diseases: hypertension (HT), type 2 diabetes mellitus (DM), rheumatoid arthritis (RA), bipolar disorder (BP), and schizophrenia (SCZ). Details of model specification, model evaluation and external validation are detailed below. 

    \subsubsection{Model Specifications}
      As the number of drugs known for treat the disease is small, classes for positive outcomes and for negative outcomes are imbalanced. In practice, the strategy of balanced class weights was adopted, which places more emphasis on the minority class to balance the importance of the positive and negative classes, following a similar strategy as our previous study \cite{zhao2018drug}. 
      
      We implemented SVM, RF and GBM models using Python package "scikit-learn" \cite{pedregosa2011scikit}. Following the strategy recommended by \cite{hsu2003practical}, we adopted two-step hyper-parameter tuning with gridsearchCV provided by the package \cite{pedregosa2011scikit}.  Specifically, we first defined a broad hyper-parameter grid with a large step size along the axis of each parameter, a and then we refined the parameter grid based on predictive performance. Optimistic bias due to hyper-parameter tuning was avoided by nested cross-validation (see below).
   
      In the study, we considered three hyperparameters for SVM, namely the kernel type , regularization parameter C and kernel coefficient $\gamma$. Here we used radial basis function (rbf) as the kernel, and C and $\gamma$ were chosen from (-5, 15) and (-15, 3) in log-2 space respectively. For RF, the number of features considered for each splitting (\textit{max\_features}) and the minimum number of samples required at a leaf node (\textit{min\_samples\_leaf}) were used to restrict the complexity of RF. We fixed the number of tree to 1000, and selected \textit{max\_features} and \textit{min\_samples\_leaf} from \{800, 1000, 1500, 2000, 3000, 5000\} and \{1, 3, 5, 10, 30, 50, 80\} respectively. Like RF, gradient boosting machine (GBM) is an ensemble method, but in a given iteration GBM gives more emphasis to observations that are misclassified in previous iterations.  For GBM, learning rate was chosen from \{0.005, 0.01, 0.015, 0.02, 0.03, 0.05\}, the number of boosting iterations from the sequence from 100 to 1001 with step size 50, maximum depth of each estimator from \{2, 3, 5, 10\} and maximum number of features from \{10, 30, 50, 100, 500, 1000\}. Subsampling proportion was fixed to 1. Finally, logistic regression with elastic net regularization (EN) was implemented using the R package "glmnet", with the mixing parameter $\alpha$ ranging from 0 to 1 (step size 0.1) and $\lambda$ using the default range by glmnet. In the model, $\alpha$ regulates the sparsity (balance between L1 and L2 penalty), and $\lambda$ is responsible for overall regularization. 
  
      In the study, a nested 5-fold cross validation (CV) was employed to choose the best hyperparameters and evaluate performance for each ML algorithm. Here we repeatedly split the data into three pieces, namely training, validation and test sets. Learning algorithms were trained on the training set and hyperparameters were chosen based on the validation set. The performance of ML models were evaluated on the test set, which is independent from the the dataset for model training and validation. Compared to simple CV, nested CV can evaluate model performance more accurately \cite{varma2006bias}. The splitting of datasets in the nested CV is the same for different ML models by setting the same random seed. 
  
    \subsubsection{Predictive Performance Evaluation}
      The performance of different ML models was evaluated by log Loss, area under the receiver operating characteristic curve (ROC-AUC) and area under the precision recall curve (PR-AUC). Log loss, related to cross-entropy, computes the negative log-likelihood of the true labels predicted by classification models, and the smaller values of log loss indicates that the model performs better. ROC-AUC measures the area under the curve of true positive rate (TPR) against the false positive rate (FPR). On the other hand, PR-AUC measures the area under the curve  precision against recall. PR-AUC may be useful in model evaluation for  imbalanced datasets\cite{davis2006relationship}. 
  
    \subsubsection{External Validation of drug targets}
      We performed validation of our approach by testing if it can 'rediscover' known or potential drug targets for diseases based on other lines of evidence. Drug target data was downloaded from Open Targets \cite{koscielny2017open} to validate our results. Note that our approach is independent of all kinds of evidence used to defined targets in the database. Intuitively, we are interested in whether the predicted probabilities of known targets from our ML models are significantly different from those of other genes.

      Open Targets provides a continuous score ranging from 0 to 1 to indicate the association strength between targets and disease. We used a sequence of cutoff ranging from 0 to 1 with step size 0.2. For each cutoff, the targets with scores greater than the cutoff were considered as drug targets for the disease. We conducted t-tests to examine if the ML-predicted probabilities of genes listed by Open Targets were significantly different from those of other unmatched genes. The false discovery rate (FDR) approach was used to control for multiple testing \cite{benjamini1995controlling}.
  
\section{Results}
  
  \subsection{Model Performance}
    Average predictive performance of different ML models, measured in log loss, AUC-ROC and AUC-PR, is presented in Table \ref{tab:target_ml_performance}. It shows that SVM performed the best cross four datasets in term of log loss, and the performance of RF and GBM were similar, slight worse than that of SVM, but the difference is small.

    \begin{table}[htbp]
      \centering
      \caption{Average predictive performance of different machine learning methods across four datasets}
      \begin{threeparttable}
        \begin{tabular}{ccccc}
        \toprule
              & \multicolumn{1}{l}{ATC DM} & \multicolumn{1}{l}{ATC HT} & \multicolumn{1}{l}
              {MEDI-HPS RA} & \multicolumn{1}{l}{ATC SCZ} \\
        \midrule
              & \multicolumn{4}{c}{\textit{Average Log Loss}} \\
        SVM   & \textbf{0.08}  & \textbf{0.2366} & \textbf{0.1209} & \textbf{0.141} \\
        RF    &       0.0836   &     0.2471      &       0.1261    &     0.1462 \\
        GBM   & 0.0875 & 0.2523 & 0.1308 & 0.1555 \\
        EN    & 0.5752 & 0.6781 & 0.6312 & 0.5114 \\
              & \multicolumn{4}{c}{\textit{Average AUC-ROC}} \\
        SVM   &       0.6232     & \textbf{0.5433} &      0.4972     & \textbf{0.7582} \\
        RF    &       0.6024     &     0.5488      &      0.5706     &      0.7377 \\
        GBM   &       0.5404     &     0.5516      &      0.5244     &      0.7474 \\
        EN    & \textbf{0.6485}  &     0.5506      & \textbf{0.5788} &      0.7496 \\
              & \multicolumn{4}{c}{\textit{Average AUC-PR}} \\
        SVM   & \textbf{0.0834} &     0.0804      &     0.0649      & \textbf{0.2402} \\
        RF    &     0.0616      &     0.0884      &     0.0471      &     0.2113 \\
        GBM   &     0.0578      & \textbf{0.0937} &     0.0485      &     0.2106 \\
        EN    &     0.0338      &     0.0792      & \textbf{0.0706} &     0.2362 \\
        \bottomrule
        \end{tabular}%
        \begin{tablenotes}
          \item 1. The figure for best performance of learning algorithms for each dataset for each evaluation metric is in bold.
          \item 2. MEDI-HPS: MEDication Indication-High Precision Subset; ATC: Anatomical Therapeutic Chemical classification.
          \item 3. Abbreviations: DM stands for diabetes mellitus, HT for hypertension, SCZ for schizophrenia, RA for rheumatoid arthritis, BP for bipolar disorders.          
        \end{tablenotes}
      \end{threeparttable}
      \label{tab:target_ml_performance}%
    \end{table}

    When considering AUC-ROC as the performance evaluation metric, we find that SVM and EN had the best performance in two datasets. Specifically, SVM outperforms other methods in ATC-HT and ATC-SCZ, while EN achieves the best performance in the other two datasets. All ML models performed better in ATC-SCZ data than in the other three datasets. In term of AUC-PR, the performance of  ML methods varied. SVM outperformed other methods in ATC-DM and ATC-SCZ datasets, but GBM and EN showed the best performance in other two datasets. Even though in one of our previous studies \cite{zhao2018drug} we have done a similar analysis on SCZ, this study on SCZ is an independent analysis from the previous one. 

  \subsection{External Validation}  
    \begin{table}[htbp]
      \centering
      \caption{enrichment for target genes of HT by results on ATC-HT dataset}
      \begin{threeparttable}
        \tabcolsep=0.10cm
        \begin{tabular}{ccccccccc}
          \toprule
                & SVM   & RF    & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{GBM} & \multicolumn{2}{c}{EN} \\
          thresholds & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} \\
          \midrule
          1     & 4.81E-03 & 5.77E-03 & 3.31E-02 & 3.97E-02 & 9.81E-02 & 1.18E-01 & 2.09E-02 & \textbf{2.60E-02} \\
          0.8   & 4.32E-03 & 5.77E-03 & 2.56E-02 & 3.84E-02 & 8.29E-02 & 1.18E-01 & 1.61E-02 & \textbf{2.60E-02} \\
          0.6   & \textbf{4.41E-04} & \textbf{2.48E-03} & 4.94E-03 & \textbf{1.48E-02} & 1.76E-02 & \textbf{5.28E-02} & \textbf{5.68E-03} & \textbf{2.60E-02} \\
          0.4   & 8.26E-04 & 2.48E-03 & \textbf{4.86E-03} & \textbf{1.48E-02} & \textbf{1.60E-02} & 5.28E-02 & 1.12E-02 & \textbf{2.60E-02} \\
          0.2   & 2.04E-03 & 4.08E-03 & 1.19E-02 & 2.38E-02 & 2.91E-02 & 5.82E-02 & 2.17E-02 & \textbf{2.60E-02} \\
          0     & 1.56E-01 & 1.56E-01 & 6.84E-01 & 6.84E-01 & 1.96E-01 & 1.96E-01 & 1.12E-01 & 1.12E-01 \\
          \bottomrule
          \end{tabular}%
          \begin{tablenotes}
            \item 1. Figures in the table are p-values calculated by two tailed t-test with alternative hypothesis that the mean predicted probability of genes listed by Open Targets is different than those of other genes. 
            \item 2. The lowest p-values/q-values for every ML model in each dataset are in bold.
            \item 3. Abbreviations are defined the same as Table \ref{tab:target_ml_performance}.  
          \end{tablenotes}
        \end{threeparttable}
        \label{tab:repurposing_enrichment_ht}%
      \end{table}%

      \begin{table}[htbp]
        \centering
        \caption{enrichment for target genes of DM by results on ATC-DM dataset}
        \begin{threeparttable}
          \tabcolsep=0.10cm
          \begin{tabular}{ccccccccc}
            \toprule
                  & SVM   & RF    & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{GBM} & \multicolumn{2}{c}{EN} \\
            thresholds & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} \\
            \midrule
            1     & 5.78E-02 & 8.67E-02 & 6.53E-02 & 9.80E-02 & 3.28E-05 & 8.62E-05 & 2.32E-03 & 4.64E-03 \\
            0.8   & 2.33E-02 & 4.66E-02 & 2.13E-02 & 6.39E-02 & 4.31E-05 & 8.62E-05 & 1.67E-03 & 4.64E-03 \\
            0.6   & \textbf{1.26E-02} & \textbf{4.66E-02} & \textbf{1.37E-02} & \textbf{6.39E-02} & \textbf{1.61E-05} & \textbf{8.62E-05} & \textbf{1.57E-03} & \textbf{4.64E-03} \\
            0.4   & 2.32E-02 & 4.66E-02 & 4.32E-02 & 8.64E-02 & 1.72E-03 & 2.58E-03 & 5.22E-03 & 7.83E-03 \\
            0.2   & 6.43E-01 & 6.43E-01 & 3.67E-01 & 4.40E-01 & 1.71E-02 & 2.05E-02 & 3.55E-02 & 4.26E-02 \\
            0     & 3.00E-01 & 3.60E-01 & 6.24E-01 & 6.24E-01 & 8.10E-01 & 8.10E-01 & 8.21E-02 & 8.21E-02 \\
            \bottomrule
            \end{tabular}%
            \begin{tablenotes}
              \item 1. Illustrations of the table are the same as Table \ref{tab:repurposing_enrichment_ht}
            \end{tablenotes}
          \end{threeparttable}
          \label{tab:repurposing_enrichment_dm}%
        \end{table}%

        \begin{table}[htbp]
          \centering
          \caption{enrichment for target genes of RA by results on MEDI-HPS RA dataset}
          \begin{threeparttable}
            \tabcolsep=0.10cm
            \begin{tabular}{ccccccccc}
              \toprule
                  & SVM   & RF    & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{GBM} & \multicolumn{2}{c}{EN} \\
            thresholds & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} \\
            \midrule
            1     & 1.18E-01 & 2.72E-01 & 6.23E-04 & 1.87E-03 & 2.01E-02 & 4.50E-02 & 9.22E-01 & 9.94E-01 \\
            0.8   & 1.36E-01 & \textbf{2.72E-01} & \textbf{3.93E-04} & \textbf{1.87E-03} & \textbf{8.53E-03} & \textbf{4.50E-02} & 9.94E-01 & 9.94E-01 \\
            0.6   & \textbf{1.18E-01} & 2.72E-01 & 1.41E-01 & 1.69E-01 & \textbf{3.67E-01} & 3.67E-01 & 9.20E-01 & 9.94E-01 \\
            0.4   & 6.44E-01 & 6.44E-01 & 1.14E-02 & 2.28E-02 & 2.25E-02 & 4.50E-02 & 2.69E-01 & 5.38E-01 \\
            0.2   & 3.12E-01 & 4.45E-01 & 8.47E-02 & 1.27E-01 & 4.15E-02 & 6.23E-02 & 8.48E-02 & \textbf{5.09E-01} \\
            0     & 3.71E-01 & 4.45E-01 & 7.01E-01 & 7.01E-01 & 1.96E-01 & 2.35E-01 & \textbf{2.56E-01} & 5.38E-01 \\
            \bottomrule
            \end{tabular}%
            \begin{tablenotes}
              \item 1. Illustrations of the table are the same as Table \ref{tab:repurposing_enrichment_ht}
            \end{tablenotes}
          \end{threeparttable}
          \label{tab:repurposing_enrichment_ra}%
        \end{table}%

        \begin{table}[htbp]
          \centering
          \caption{enrichment for target genes of DM by results on ATC SCZ dataset}
          \begin{threeparttable}
            \tabcolsep=0.10cm
            \begin{tabular}{ccccccccc}
            \toprule
                  & SVM   & RF    & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{GBM} & \multicolumn{2}{c}{EN} \\
            thresholds & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} \\
            \midrule
            1     & 3.32E-01 & 4.98E-01 & 2.84E-01 & 5.68E-01 & \textbf{2.57E-01} & \textbf{7.92E-01} & 3.56E-01 & \textbf{5.76E-01} \\
            0.8   & 4.66E-01 & 5.59E-01 & 2.47E-01 & \textbf{5.68E-01} & 2.64E-01 & 7.92E-01 & \textbf{2.80E-01} & 5.76E-01 \\
            0.6   & 2.18E-02 & 6.54E-02 & 7.78E-01 & 8.97E-01 & 9.94E-01 & 9.94E-01 & 7.47E-01 & 7.47E-01 \\
            0.4   & \textbf{1.91E-02} & 6.54E-02 & 8.62E-01 & 8.97E-01 & 7.97E-01 & 9.94E-01 & 3.84E-01 & 5.76E-01 \\
            0.2   & 7.00E-02 & \textbf{1.40E-01} & 8.97E-01 & 8.97E-01 & 5.42E-01 & 9.94E-01 & 7.18E-01 & 7.47E-01 \\
            0     & 7.11E-01 & 7.11E-01 & \textbf{1.85E-01} & 5.68E-01 & 9.01E-01 & 9.94E-01 & 3.14E-01 & 5.76E-01 \\
            \bottomrule
            \end{tabular}%
            \begin{tablenotes}
              \item 1. Illustrations of the table are the same as Table \ref{tab:repurposing_enrichment_ht}
            \end{tablenotes}
          \end{threeparttable}
          \label{tab:repurposing_enrichment_scz}%
        \end{table}%


        \begin{table}[htbp]
          \centering
          \caption{enrichment for target genes of BP by results on ATC SCZ dataset}
          \begin{threeparttable}
            \tabcolsep=0.10cm
            \begin{tabular}{ccccccccc}
            \toprule
                  & SVM   & RF    & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{GBM} & \multicolumn{2}{c}{EN} \\
            thresholds & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} & \textit{P-value} & \textit{q-value} \\
            \midrule
            1     & 4.14E-01 & 6.99E-01 & 7.24E-01 & 7.97E-01 & 5.88E-01 & 7.06E-01 & 5.59E-01 & 6.71E-01 \\
            0.8   & 4.66E-01 & 6.99E-01 & 7.58E-01 & \textbf{7.97E-01} & 9.43E-01 & 9.43E-01 & 9.43E-01 & 9.43E-01 \\
            0.6   & 8.57E-01 & 8.57E-01 & 6.84E-01 & 7.97E-01 & 2.56E-01 & 3.84E-01 & 2.90E-02 & 5.80E-02 \\
            0.4   & 8.57E-01 & 8.57E-01 & 6.84E-01 & 7.97E-01 & 2.56E-01 & 3.84E-01 & 2.90E-02 & 5.80E-02 \\
            0.2   & 4.13E-01 & 6.99E-01 & \textbf{3.17E-01} & 7.97E-01 & \textbf{6.03E-02} & \textbf{3.62E-01} & \textbf{1.45E-03} & \textbf{8.70E-03} \\
            0     & \textbf{1.31E-02} & \textbf{7.86E-02} & 7.97E-01 & 7.97E-01 & 1.91E-01 & 3.84E-01 & 4.76E-01 & 6.71E-01 \\
            \midrule
            \end{tabular}%
            \begin{tablenotes}
              \item 1. Illustrations of the table are the same as Table \ref{tab:repurposing_enrichment_ht}
            \end{tablenotes}
          \end{threeparttable}
          \label{tab:repurposing_enrichment_bp}%
        \end{table}%

    The results of enrichment test (for validation of drug targets) for over-expressed genes are shown in Tables \ref{tab:repurposing_enrichment_ht}, \ref{tab:repurposing_enrichment_dm}, \ref{tab:repurposing_enrichment_ra}, \ref{tab:repurposing_enrichment_scz}, \ref{tab:repurposing_enrichment_bp}. No statistically significant enrichment was observed for KD genes, and the results are shown in supplementary tables. 
    
    For DM and HT (\ref{tab:repurposing_enrichment_ht}, \ref{tab:repurposing_enrichment_dm}), we observed significant enrichment across multiple thresholds with FDR $< 0.05$, indicating the proposed method indeed 're-discovered' known targets more than expected by chance. For RA, significant enrichment was mainly observed for prediction models based on RF or GBM. \ref{tab:repurposing_enrichment_ra}). For SCZ and BP which shared anti-psychotics as treatment, the enrichment was not as strong, but suggestive enrichment (FDR $< 0.2 $) were observed for SVM in SCZ and EN in BP ( \ref{tab:repurposing_enrichment_scz}  \ref{tab:repurposing_enrichment_bp} )
     
    \textbf{(comment: should show the top targets for all diseases, eg top K targets with highest predicted probability and bottom K with lowest pred prob. in a supplementary table)} , k=5 or 10
    comment: also consider a table showing brief description of evidence of each target discussed in main text 

  \subsection{Literature Support}
    Our model generated several potential druggable targets for different diseases. We extracted the top candidates (30 with the highest and lowest predicted probabilities respectively) and we highlight several targets that are supported by previous studies here. 

    Some of the top potential DM drug targets  suggested by our model  included SGK1, ESR1, CISH, MAPK4K4, UGCG. Our model suggests that inhibition of  SGK1 is may be therapeutically useful on DM. In diabetic animal models, SGK1 expressions were up-regulated \cite{hills2006high, xuebin2005expression,chang2007enhancement}, which is likely caused by production of advanced glycation products (AGE) \cite{hills2006high,chang2007enhancement}. SGK1 is critical to the development of diabetic neuropathy, and inhibition of SGK1 by fluvastatin has shown favorable effects in ameliorating progression of DM \cite{xuebin2005expression}.  CISH (Cytokine-inducible SH2) containing Cish protein is involved in the signaling pathway of  human growth hormone (hGC), and induction of this pathway by hGC minigene has been shown to promote beta-islet cell proliferation in murine model \cite{baan2015transgenic}. MAPK4K4 is also a drug target suggested by our model for DM. In a cell culture experiment, inhibition of MAPK4K4 by RNA interference was able to completely reverse the insulin resisting effect of TNF-alpha \cite{bouzakri2007map4k4}. UGCG (Ceramide and its metabolites) is known as an inhibitor of insulin sensitivity. Aerts et al. demonstrated that both ceramide and its downstream metabolites could reduce insulin sensitivity in\textit{ vivo} and that treatment with AMP-DNM could reverse insulin insensitivity \cite{aerts2007pharmacological}. 
  
    Our approach also identified several promising targets for rheumatoid arthritis. It has long been shown that substance P inhibition has an important role in the pathophysiology of RA \cite{lisowska2015substance,garrett1992role,green2005gastrin,keeble2004role,lotz1987substance,okamura2017dual,lam1990mediators,lam1991neurogenic}. It serves as a pain transmitter, exacerbates the inflammatory process in arthritic joints and worsens disease progression. Our study identifies SP inhibition as a favorable drug target, and this has already been proven in previous studies. For example, substance P has been shown to improve actions of dexamethasone for the treatment of arthritis in rats \cite{lam2010substance}. CTNNBIP-1, which encodes for $\beta$-catenin, is identified as a promising therapeutic target by our model, and it has been studied extensively. $\beta$-catenin is a critical player of the Wnt signaling pathway that initiates arthritic progression and development in joints \cite{sen2005wnt,zhou2017wnt}, and dysfunction of this pathway was considered a disease model for RA \cite{wu2010beta,zhou2017wnt}. There is a pool of potential pharmacological interventions that have been shown to thwart, improve or even repair disease condition at arthritic joints, including herbal isolate Artemisinin \cite{zhong2018artemisinin}, small molecular inhibitors \cite{lietman2018inhibition,landman2013small,landman2013small,dell2017pharmacological}, FDA approved fluoxetine, an antidepressant in the class of SSRI \cite{miyamoto2017fluoxetine}, and even naturally occurring polyphenol from diet \cite{li2018resveratrol}. 
    
    PSMB8 encodes the $\beta$5i subunit, known as LMP7 (large multifunctional protease 7), and LMP7 is a catalytic subunit of immunoproteasomes in patients with JMP syndrome \cite{agarwal2010psmb8}. Basler et al. found that LMP7 alone was not sufficient, and that LMP2 must also be co-inhibited in order to block immunity \cite{basler2018co}. These findings suggest that selective inhibitors for LMP7, such as ONX 0914, which is already used for other autoimmune diseases \cite{althof2018immunoproteasome,liu2017onx,verbrugge2012targeting}, may be repositioned to treat RA. Our model also suggests that antagonizing NR4A2 could help treat RA, which has been proved by previous findings. NR4A2 is an orphan nuclear receptor that is responsible for proinflammatory responses particularly to IL-8 in RA \cite{aherne2009identification}. It was also found that it plays as a downstream response element of TNF-alpha \cite{mix2012orphan} as well as a transcription factor for the immunomodulatory peptide hormone prolactin \cite{mccoy2015orphan}. TNF is a known target rediscovered by our model. Currently, many of the xenobiotic DMARDs in clinical use were developed against TNF. Our SVM model shows inhibitors of this receptor may bring about therapeutic effects \cite{aletaha2018diagnosis}.
  
    Antagonizing angiotensin II and glucocorticoid is a well-known popular therapeutic approach to treat hypertension. Our model strongly suggests that angiotensin II and glucocorticoid be therapeutic targets of hypertension. Identification of the two targets proves the validity of our model and also demonstrates that our approach can produce results compatible to traditional pharmacological interventions. Interestingly, our model well learned the pattern of biological mechanisms for decreasing or increasing blood pressure. For instance, our model strongly recommends that inhibiting corticosteroid-binding protein reduces blood pressure, since SERPINA6 deficiency usually leads low blood pressure \cite{torpy2001familial}. 
  
    Our method discover multiple potential targets for SCZ that are also appeared in GWAS publications \cite{zhang2015functional,golimbet2014study,lee2013pathway,sinclair2012glucocorticoid,ahmad2015association,kishi2011sirt1,athanasiou2011candidate,hoenicka2010sexually,tein2008short,sun2004cldn5,chen2004case,yu2008association,hashimoto2005functional}, independently supporting the validity of our approach. For example, PIP5K2A acts as an agonist of amino acid transporter EAAT3, which facilities glutamate reuptake. Glutamatergic transmission has been implicated in SCZ as an important mechanism of disease.

\section{Discussion}
  In this study, we presented a novel computational approach to identify promising drug targets by incorporating gene expression profiles. This approach is general as it can widely incorporate any classification algorithms. Four state-of-the art machine learning methods were used to demonstrate the potential of our approach, and their performances were compared by three different evaluation metrics. Results of enrichment test show that top genes from our models are enriched for targets from Open Targets for diabetes mellitus, hypertension, schizophrenia, bipolar disorder, and rheumatoid arthritis. Some of the top potential drug targets identified by our approach are also supported by previous studies. As far as we know, this work is the first to directly employ machine learning methods on both drug-induced and genetically-perturbed expression data to discover potential drug targets for specific diseases. 

  The study adopted four ML methods, which are capable of learning either linear or nonlinear relationship present in data. Because the number of variables is much larger than the number of observations (p $\gg$ n), certain regularization methods are required. Logistic regression with elastic net penalty (EN) can automatically select features that contribute the most to prediction. In our case, the performance of EN is quite reasonable, even though it only models linear relationship. SVM uses kernel tricks to map the feature into higher dimension feature space. On the other hand, random forests (RF) and gradient boosting machine (GBM) are well-known tree-based methods. The basic idea behind them is to assemble a number of 'weak' (tree-based) learners to make accurate predictions. A main difference between the two is that GBM is a sequential tree model, which adjusts the importance of observations in learning according to the performance of previously fitted trees. For  GBM and RF, their performances are comparable overall across the four datasets. In this study, we do not put our emphasis on particular algorithms, since we are interested in demonstrating the potential of our framework in prioritizing drug target candidates. Although a number of targets listed are supported by previous studies, further experimental validation is necessary to confirm the findings. The presented algorithm aims to \textit{prioritize} drug targets, which may be useful as an independent source of evidence to  support further experimental studies of certain candidates. 

  We have employed enrichment tests to validate the overall validity of our approach. While animal studies or other experimental validations may provide stronger evidence for individual targets, such validation cannot be easily carried out on a large number of targets. Also, validation on a few targets cannot provide evidence for the \textit{overall validity }of the presented framework, because there may be chance findings. 

  Our approach is general and highly flexible. However, there are several limitations. One limitation is that our dataset for ML prediction model building is highly imbalanced, as usually only a small number of drugs are indicated for each disease. In order to address this issue we increased class weight of the minority group. There are also other strategies to address issue such as SMOTE (Synthetic Minority Over-sampling Technique) \cite{chawla2002smote}, but whether strategies like SMOTE can address this issue in high dimensional settings is still unclear. This will be a topic further investigation. Further, we may also resort to more advanced or recently developed machine learning methods, such as deep neural networks, to uncover new targets. However, such methods may be more useful in larger samples. Another important aspect is that we observed significant enrichment in OE datasets but not in KD datasets. One hypothesis is that some off-target effects may interfere with the expression profiles in KD experiments, leading to greater difficulties in finding relevant drug targets. How to overcome or reduce the influence of off-target effects remain an area for further studies. 

\section{Conclusion}
  This study presented a general computational framework to prioritize drug targets for various diseases. Under the framework, different kinds of ML methods can be utilized.  We applied four ML methods to identify potential drug target of five disorders. External validation shows that the top candidates are enriched for targets selected by independent lines of evidence from a large external database(Open Targets). Some top target genes were also supported by previous studies.
  
  Finding promising drug targets for diseases is crucial to drug development. However, it is impractical to perform in-depth experimental studies on every possible target for each disease. Computational methods offer a cheap, fast and systematic high-throughput approach to guide prioritization of drug targets. We hope our presented framework will provide an additional way to prioritize drug targets for development, which is independent of and may be combined with other existing sources of data.

\chapterend